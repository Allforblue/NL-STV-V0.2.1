import asyncio
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
import json

# å¯¼å…¥ä½ çš„æ ¸å¿ƒæ¨¡å—
from core.llm.AI_client import AIClient
from core.services.workflow import AnalysisWorkflow
from core.schemas.interaction import InteractionPayload


async def test_workflow():
    print("ğŸš€ å¼€å§‹åç«¯é›†æˆæµ‹è¯•...")

    # 1. å‡†å¤‡æ¨¡æ‹Ÿæ•°æ® (Mock Data Context)
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„å‡ºç§Ÿè½¦è®¢å•æ•°æ®é›†
    data = {
        'trip_id': [1, 2, 3, 4, 5],
        'pickup_time': ['2023-10-01 08:00', '2023-10-01 09:00', '2023-10-01 10:00', '2023-10-01 11:00',
                        '2023-10-01 12:00'],
        'lat': [31.23, 31.24, 31.22, 31.25, 31.23],
        'lon': [121.47, 121.48, 121.46, 121.49, 121.47],
        'fare': [50.0, 45.5, 60.0, 30.0, 55.0],
        'district': ['Jingan', 'Huangpu', 'Jingan', 'Pudong', 'Huangpu']
    }
    df_taxi = pd.DataFrame(data)
    df_taxi['pickup_time'] = pd.to_datetime(df_taxi['pickup_time'])

    # è½¬æ¢ä¸º GeoDataFrame
    gdf_taxi = gpd.GeoDataFrame(
        df_taxi,
        geometry=gpd.points_from_xy(df_taxi.lon, df_taxi.lat),
        crs="EPSG:4326"
    )

    data_context = {"df_taxi": gdf_taxi}
    print("âœ… æ¨¡æ‹Ÿæ•°æ®ä¸Šä¸‹æ–‡å·²å‡†å¤‡ (å˜é‡å: df_taxi)")

    # 2. æ¨¡æ‹Ÿè¯­ä¹‰æ‘˜è¦ (Mock Summaries)
    # è¿™æ˜¯ SemanticAnalyzer åº”è¯¥è¾“å‡ºçš„å†…å®¹
    mock_summaries = [{
        "variable_name": "df_taxi",
        "file_info": {"name": "mock_taxi_data.csv", "path": "mock/path"},
        "semantic_analysis": {
            "dataset_type": "TRAJECTORY",
            "description": "æ¨¡æ‹Ÿçš„åŸå¸‚å‡ºç§Ÿè½¦è®¢å•æ•°æ®",
            "semantic_tags": {
                "trip_id": "ID_KEY",
                "pickup_time": "ST_TIME",
                "lat": "ST_LAT",
                "lon": "ST_LON",
                "fare": "BIZ_PRICE",
                "district": "BIZ_CAT",
                "geometry": "ST_GEO"
            }
        }
    }]
    print("âœ… æ¨¡æ‹Ÿè¯­ä¹‰æ‘˜è¦å·²å‡†å¤‡")

    # 3. åˆå§‹åŒ–å·¥ä½œæµ
    # è¯·ç¡®ä¿ä½ çš„ç¯å¢ƒå˜é‡ä¸­å·²è®¾ç½®äº† API Key
    client = AIClient(model_name="deepseek-chat")
    workflow = AnalysisWorkflow(client)
    print("âœ… AnalysisWorkflow åˆå§‹åŒ–æˆåŠŸ")

    # 4. æ¨¡æ‹Ÿç”¨æˆ·æé—® (InteractionPayload)
    payload = InteractionPayload(
        session_id="test_session_001",
        query="åˆ†æä¸åŒåŒºåŸŸçš„æ‰“è½¦è´¹åˆ†å¸ƒæƒ…å†µï¼Œå¹¶åœ¨åœ°å›¾ä¸Šå±•ç¤º",
        force_new=True
    )

    # 5. è¿è¡Œå·¥ä½œæµ
    try:
        print("\nğŸ¤– AI æ­£åœ¨å¤„ç†è¯·æ±‚ (è¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ)...")
        dashboard = await workflow.execute_step(payload, mock_summaries, data_context)

        print("\n" + "=" * 50)
        print("ğŸ‰ æµ‹è¯•æˆåŠŸï¼åç«¯è¿”å›äº† DashboardSchema")
        print("=" * 50)

        # éªŒè¯ç»“æœ
        print(f"çœ‹æ¿æ ‡é¢˜: {dashboard.title}")
        print(f"ç»„ä»¶æ•°é‡: {len(dashboard.components)}")

        for comp in dashboard.components:
            print(f"\n[ç»„ä»¶ ID: {comp.id}]")
            print(f"- ç±»å‹: {comp.type}")
            print(f"- æ ‡é¢˜: {comp.title}")
            print(f"- å¸ƒå±€: {comp.layout}")

            if comp.type == "insight" and comp.insight_config:
                print(f"- ğŸ¤– AI æ´å¯Ÿæ‘˜è¦: {comp.insight_config.summary}")
                print(f"- ğŸ¤– AI è¯¦ç»†è§£é‡Š: {comp.insight_config.detail}")

        # æ£€æŸ¥ç”Ÿæˆçš„ä»£ç ï¼ˆåœ¨ metadata ä¸­ï¼‰
        if "last_code" in dashboard.metadata:
            print("\n" + "-" * 30)
            print("ğŸ“ AI ç”Ÿæˆçš„æ‰§è¡Œä»£ç ç‰‡æ®µ:")
            print(dashboard.metadata["last_code"][:300] + "...")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(test_workflow())