import logging
from typing import Dict, Any, Optional, List
from pathlib import Path

# --- å¼•å…¥å¿…è¦çš„ä¸‹å±‚æ¨¡å— ---
from core.ingestion.ingestion import IngestionManager
from core.profiler.basic_stats import get_dataset_fingerprint

logger = logging.getLogger(__name__)


class SessionManager:
    """
    ä¼šè¯ç®¡ç†å™¨ (å®Œæ•´ç‰ˆ)ï¼š
    è´Ÿè´£ä¼šè¯çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼Œå¹¶åè°ƒæ•°æ®çš„åˆå§‹åŠ è½½ä¸ç”»åƒç”Ÿæˆã€‚
    æ”¯æŒä»é‡‡æ ·æ¨¡å¼(å¿«é€Ÿå“åº”)è‡ªåŠ¨åˆ‡æ¢åˆ°å…¨é‡æ¨¡å¼(ç²¾å‡†åˆ†æ)ã€‚
    """

    def __init__(self):
        # å†…å­˜å­˜å‚¨å­—å…¸
        # Structure: { session_id: { "summaries": [...], "data_context": {...}, "history": [...] } }
        self._sessions: Dict[str, Dict[str, Any]] = {}
        self.ingestion_manager = IngestionManager()

    def create_session(self, session_id: str, file_paths: List[str]) -> Dict[str, Any]:
        """
        åˆ›å»ºæ–°ä¼šè¯ï¼š
        1. åŠ è½½æ•°æ® (é»˜è®¤é‡‡æ ·æ¨¡å¼ï¼Œä¿è¯ä¸Šä¼ æ¥å£ç§’å¼€)
        2. ç”Ÿæˆç”»åƒ (Profiling)
        3. åˆå§‹åŒ–çŠ¶æ€
        """
        logger.info(f"æ­£åœ¨åˆå§‹åŒ–ä¼šè¯ {session_id}ï¼Œå¤„ç†æ–‡ä»¶: {file_paths}")

        # 1. åˆå§‹åŠ è½½ï¼šä½¿ç”¨é‡‡æ ·æ¨¡å¼ (Fast)
        data_context = self.ingestion_manager.load_all_to_context(file_paths, use_full=False)

        if not data_context:
            logger.warning(f"ä¼šè¯ {session_id} æœªèƒ½åŠ è½½ä»»ä½•æœ‰æ•ˆæ•°æ®ã€‚")

        # 2. ç”Ÿæˆæ•°æ®æ‘˜è¦ (Summaries)
        summaries = []
        for var_name, df in data_context.items():
            try:
                # [è·¯å¾„åŒ¹é…é€»è¾‘] æ ¹æ® var_name åå‘æŸ¥æ‰¾åŸå§‹æ–‡ä»¶è·¯å¾„
                matched_path = "unknown"
                for p in file_paths:
                    fname_stem = Path(p).stem.lower()
                    if fname_stem in var_name:
                        matched_path = str(p)
                        break

                # å…œåº•é€»è¾‘
                if matched_path == "unknown" and file_paths:
                    matched_path = file_paths[0]

                # è°ƒç”¨ profiler ç”ŸæˆæŒ‡çº¹ä¿¡æ¯
                fingerprint = get_dataset_fingerprint(df)

                # æ„é€ æ ‡å‡†çš„ summary ç»“æ„
                summary = {
                    "variable_name": var_name,
                    "file_info": {
                        "path": matched_path,
                        "rows": fingerprint["rows"],
                        "cols": fingerprint["cols"]
                    },
                    "basic_stats": fingerprint,
                    "semantic_analysis": {
                        "description": f"Loaded from {Path(matched_path).name}",
                        "semantic_tags": {}
                    }
                }
                summaries.append(summary)
            except Exception as e:
                logger.error(f"ä¸ºå˜é‡ {var_name} ç”Ÿæˆç”»åƒå¤±è´¥: {e}")

        # 3. å­˜å…¥ä¼šè¯çŠ¶æ€
        session_state = {
            "session_id": session_id,
            "data_context": data_context,
            "summaries": summaries,
            "file_paths": file_paths,  # [æ–°å¢] ä¿å­˜åŸå§‹æ–‡ä»¶è·¯å¾„ï¼Œæ–¹ä¾¿åç»­é‡è½½
            "is_full_data": False,  # [æ–°å¢] æ ‡è®°å½“å‰æ˜¯é‡‡æ ·æ•°æ®
            "last_workflow_state": None,
            "history": []
        }

        self._sessions[session_id] = session_state
        logger.info(f"âœ… ä¼šè¯ {session_id} å°±ç»ª (é‡‡æ ·æ¨¡å¼)ã€‚åŒ…å«å˜é‡: {list(data_context.keys())}")

        return session_state

    def ensure_full_data_context(self, session_id: str):
        """
        [æ–°å¢] ç¡®ä¿å½“å‰ä¼šè¯çš„æ•°æ®æ˜¯å…¨é‡çš„ã€‚
        å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿›è¡Œåˆ†æï¼Œä¼šè§¦å‘å…¨é‡åŠ è½½ï¼ˆè€—æ—¶æ“ä½œï¼‰ã€‚
        """
        session = self.get_session(session_id)
        if not session:
            return

        # å¦‚æœå·²ç»æ˜¯å…¨é‡æ•°æ®ï¼Œç›´æ¥è¿”å›
        if session.get("is_full_data", False):
            return

        logger.info(f">>> æ­£åœ¨å°†ä¼šè¯ {session_id} åˆ‡æ¢ä¸ºã€å…¨é‡æ•°æ®æ¨¡å¼ã€‘ä»¥ä¿è¯åˆ†æå‡†ç¡®æ€§...")

        try:
            file_paths = session.get("file_paths", [])
            # é‡æ–°åŠ è½½ï¼Œè¿™æ¬¡ use_full=True
            full_context = self.ingestion_manager.load_all_to_context(file_paths, use_full=True)

            # æ›´æ–° Session ä¸­çš„ data_context
            # æ³¨æ„ï¼šsummaries ä¸éœ€è¦æ›´æ–°ï¼Œå› ä¸ºåŸºç¡€ç»Ÿè®¡ç‰¹å¾ï¼ˆåˆ—åã€ç±»å‹ï¼‰åœ¨å…¨é‡å’Œé‡‡æ ·ä¸‹é€šå¸¸æ˜¯ä¸€è‡´çš„ï¼Œ
            # ä¸”è¡Œæ•°å·®å¼‚ä¸å½±å“ Schema ç†è§£ï¼Œåè€Œèƒ½èŠ‚çœ LLM Tokenã€‚
            session["data_context"] = full_context
            session["is_full_data"] = True

            logger.info(f"âœ… å…¨é‡æ•°æ®åŠ è½½å®Œæˆã€‚")
        except Exception as e:
            logger.error(f"åˆ‡æ¢å…¨é‡æ•°æ®å¤±è´¥: {e}")
            # å¤±è´¥åˆ™ä¿æŒåŸæ ·ï¼Œé¿å…ç³»ç»Ÿå´©æºƒ

    def get_session(self, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¼šè¯å¯¹è±¡"""
        return self._sessions.get(session_id)

    def update_session_metadata(self, session_id: str, metadata: Dict[str, Any]):
        """
        æ›´æ–° Workflow æ‰§è¡Œåçš„å…ƒæ•°æ® (å¦‚ last_code, last_layout)
        """
        if session_id in self._sessions:
            if "last_workflow_state" not in self._sessions[session_id]:
                self._sessions[session_id]["last_workflow_state"] = {}

            # åˆå¹¶æ›´æ–°
            current_state = self._sessions[session_id]["last_workflow_state"] or {}
            current_state.update(metadata)
            self._sessions[session_id]["last_workflow_state"] = current_state

    def append_history(self, session_id: str, query: str, response: str):
        """è®°å½•å¯¹è¯å†å²"""
        if session_id in self._sessions:
            self._sessions[session_id]["history"].append({
                "query": query,
                "response": response
            })

    def delete_session(self, session_id: str):
        """æ¸…ç†ä¼šè¯"""
        if session_id in self._sessions:
            # å¸®åŠ© GC å›æ”¶
            self._sessions[session_id]["data_context"].clear()
            del self._sessions[session_id]
            logger.info(f"ğŸ—‘ï¸ ä¼šè¯ {session_id} å·²ç§»é™¤ã€‚")


# å•ä¾‹æ¨¡å¼
session_service = SessionManager()